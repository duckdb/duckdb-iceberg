# name: test/sql/local/irc/update/update_join_duplicates.test
# description: Test ducklake update using a join with duplicates
# group: [update]

require-env ICEBERG_SERVER_AVAILABLE

require avro

require parquet

require iceberg

require httpfs

# Do not ignore 'HTTP' error messages!
set ignore_error_messages

statement ok
CALL enable_logging('HTTP');

statement ok
set logging_level='debug'

statement ok
CREATE SECRET (
    TYPE S3,
    KEY_ID 'admin',
    SECRET 'password',
    ENDPOINT '127.0.0.1:9000',
    URL_STYLE 'path',
    USE_SSL 0
);


statement ok
ATTACH '' AS my_datalake (
    TYPE ICEBERG,
    CLIENT_ID 'admin',
    CLIENT_SECRET 'password',
    ENDPOINT 'http://127.0.0.1:8181'
);

statement ok
DROP TABLE IF EXISTS my_datalake.default.test;

statement ok
CREATE TABLE my_datalake.default.test AS SELECT i id FROM range(5) t(i);

statement ok
CREATE TEMPORARY TABLE updated_rows AS FROM range(0, 10, 2) t(update_id) UNION ALL FROM range(0, 10, 2);

# duplicate row-id updates are not yet supported
statement ok
BEGIN

statement ok
INSERT INTO my_datalake.default.test FROM range(5, 10)

statement error
UPDATE my_datalake.default.test SET id=id+1000 FROM updated_rows WHERE id=updated_rows.update_id
----
The same row was updated multiple times

statement ok
ROLLBACK

# we can update through a join if we filter out the duplciate row ids
statement ok
BEGIN

statement ok
INSERT INTO my_datalake.default.test FROM range(5, 10)

statement ok
UPDATE my_datalake.default.test SET id=id+1000 FROM (SELECT DISTINCT update_id FROM updated_rows) updated_rows WHERE id=updated_rows.update_id

query III
SELECT COUNT(*), SUM(id), AVG(id) FROM my_datalake.default.test
----
10	5045	504.5

statement ok
COMMIT

query III
SELECT COUNT(*), SUM(id), AVG(id) FROM my_datalake.default.test
----
10	5045	504.5


