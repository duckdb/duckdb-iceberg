# name: test/sql/local/irc/insert/test_big_insert.test
# group: [insert]

require-env ICEBERG_SERVER_AVAILABLE

require avro

require parquet

require iceberg

require httpfs

# Do not ignore 'HTTP' error messages!
set ignore_error_messages

statement ok
set enable_logging=true

statement ok
set logging_level='debug'

statement ok
CREATE SECRET (
    TYPE S3,
    KEY_ID 'admin',
    SECRET 'password',
    ENDPOINT '127.0.0.1:9000',
    URL_STYLE 'path',
    USE_SSL 0
);


statement ok
ATTACH '' AS my_datalake (
    TYPE ICEBERG,
    CLIENT_ID 'admin',
    CLIENT_SECRET 'password',
    ENDPOINT 'http://127.0.0.1:8181'
);

# Default TARGET_FILE_SIZE = 8.4MB
# We create ~18MB of data, which spreads out over 3 files
query I
INSERT INTO my_datalake.default.insert_test_big SELECT i, concat('thisisalongstring', i) FROM range(2000000) t(i)
----
2000000

query II
explain analyze select * from my_datalake.default.insert_test_big
----
analyzed_plan	<REGEX>:.*Total Files Read: 3.*
